{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3515934,"sourceType":"datasetVersion","datasetId":2115769},{"sourceId":12651494,"sourceType":"datasetVersion","datasetId":7995236}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\nmeta_path = \"/kaggle/input/pancreas-ct/Pancreas-CT/metadata.csv\"\ndf = pd.read_csv(meta_path)\n\ndf.head()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-09T04:44:51.132963Z","iopub.execute_input":"2026-02-09T04:44:51.133186Z","iopub.status.idle":"2026-02-09T04:44:52.252331Z","shell.execute_reply.started":"2026-02-09T04:44:51.133137Z","shell.execute_reply":"2026-02-09T04:44:52.251675Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"                                                     Series UID  Collection  \\\n1.2.826.0.1.3680043.2.1125.1.663761548252932059...  Pancreas-CT         NaN   \n1.2.826.0.1.3680043.2.1125.1.688789599848377264...  Pancreas-CT         NaN   \n1.2.826.0.1.3680043.2.1125.1.644314406605294134...  Pancreas-CT         NaN   \n1.2.826.0.1.3680043.2.1125.1.541969314475412820...  Pancreas-CT         NaN   \n1.2.826.0.1.3680043.2.1125.1.641969959866553451...  Pancreas-CT         NaN   \n\n                                                                               3rd Party Analysis  \\\n1.2.826.0.1.3680043.2.1125.1.663761548252932059...  https://doi.org/10.7937/K9/TCIA.2016.tNB1kqBU   \n1.2.826.0.1.3680043.2.1125.1.688789599848377264...  https://doi.org/10.7937/K9/TCIA.2016.tNB1kqBU   \n1.2.826.0.1.3680043.2.1125.1.644314406605294134...  https://doi.org/10.7937/K9/TCIA.2016.tNB1kqBU   \n1.2.826.0.1.3680043.2.1125.1.541969314475412820...  https://doi.org/10.7937/K9/TCIA.2016.tNB1kqBU   \n1.2.826.0.1.3680043.2.1125.1.641969959866553451...  https://doi.org/10.7937/K9/TCIA.2016.tNB1kqBU   \n\n                                                   Data Description URI  \\\n1.2.826.0.1.3680043.2.1125.1.663761548252932059...        PANCREAS_0002   \n1.2.826.0.1.3680043.2.1125.1.688789599848377264...        PANCREAS_0001   \n1.2.826.0.1.3680043.2.1125.1.644314406605294134...        PANCREAS_0003   \n1.2.826.0.1.3680043.2.1125.1.541969314475412820...        PANCREAS_0004   \n1.2.826.0.1.3680043.2.1125.1.641969959866553451...        PANCREAS_0005   \n\n                                                                                           Subject ID  \\\n1.2.826.0.1.3680043.2.1125.1.663761548252932059...  1.2.826.0.1.3680043.2.1125.1.67817772420731955...   \n1.2.826.0.1.3680043.2.1125.1.688789599848377264...  1.2.826.0.1.3680043.2.1125.1.38381854871216336...   \n1.2.826.0.1.3680043.2.1125.1.644314406605294134...  1.2.826.0.1.3680043.2.1125.1.88257539048181233...   \n1.2.826.0.1.3680043.2.1125.1.541969314475412820...  1.2.826.0.1.3680043.2.1125.1.45801723417932600...   \n1.2.826.0.1.3680043.2.1125.1.641969959866553451...  1.2.826.0.1.3680043.2.1125.1.29048236109077859...   \n\n                                                   Study UID  \\\n1.2.826.0.1.3680043.2.1125.1.663761548252932059...  Pancreas   \n1.2.826.0.1.3680043.2.1125.1.688789599848377264...  Pancreas   \n1.2.826.0.1.3680043.2.1125.1.644314406605294134...  Pancreas   \n1.2.826.0.1.3680043.2.1125.1.541969314475412820...  Pancreas   \n1.2.826.0.1.3680043.2.1125.1.641969959866553451...  Pancreas   \n\n                                                   Study Description  \\\n1.2.826.0.1.3680043.2.1125.1.663761548252932059...        11-24-2015   \n1.2.826.0.1.3680043.2.1125.1.688789599848377264...        11-24-2015   \n1.2.826.0.1.3680043.2.1125.1.644314406605294134...        11-24-2015   \n1.2.826.0.1.3680043.2.1125.1.541969314475412820...        11-24-2015   \n1.2.826.0.1.3680043.2.1125.1.641969959866553451...        11-24-2015   \n\n                                                   Study Date  \\\n1.2.826.0.1.3680043.2.1125.1.663761548252932059...   Pancreas   \n1.2.826.0.1.3680043.2.1125.1.688789599848377264...   Pancreas   \n1.2.826.0.1.3680043.2.1125.1.644314406605294134...   Pancreas   \n1.2.826.0.1.3680043.2.1125.1.541969314475412820...   Pancreas   \n1.2.826.0.1.3680043.2.1125.1.641969959866553451...   Pancreas   \n\n                                                    Series Description  \\\n1.2.826.0.1.3680043.2.1125.1.663761548252932059...                 NaN   \n1.2.826.0.1.3680043.2.1125.1.688789599848377264...                 NaN   \n1.2.826.0.1.3680043.2.1125.1.644314406605294134...                 NaN   \n1.2.826.0.1.3680043.2.1125.1.541969314475412820...                 NaN   \n1.2.826.0.1.3680043.2.1125.1.641969959866553451...                 NaN   \n\n                                                   Manufacturer  \\\n1.2.826.0.1.3680043.2.1125.1.663761548252932059...           CT   \n1.2.826.0.1.3680043.2.1125.1.688789599848377264...           CT   \n1.2.826.0.1.3680043.2.1125.1.644314406605294134...           CT   \n1.2.826.0.1.3680043.2.1125.1.541969314475412820...           CT   \n1.2.826.0.1.3680043.2.1125.1.641969959866553451...           CT   \n\n                                                            Modality  \\\n1.2.826.0.1.3680043.2.1125.1.663761548252932059...  CT Image Storage   \n1.2.826.0.1.3680043.2.1125.1.688789599848377264...  CT Image Storage   \n1.2.826.0.1.3680043.2.1125.1.644314406605294134...  CT Image Storage   \n1.2.826.0.1.3680043.2.1125.1.541969314475412820...  CT Image Storage   \n1.2.826.0.1.3680043.2.1125.1.641969959866553451...  CT Image Storage   \n\n                                                               SOP Class Name  \\\n1.2.826.0.1.3680043.2.1125.1.663761548252932059...  1.2.840.10008.5.1.4.1.1.2   \n1.2.826.0.1.3680043.2.1125.1.688789599848377264...  1.2.840.10008.5.1.4.1.1.2   \n1.2.826.0.1.3680043.2.1125.1.644314406605294134...  1.2.840.10008.5.1.4.1.1.2   \n1.2.826.0.1.3680043.2.1125.1.541969314475412820...  1.2.840.10008.5.1.4.1.1.2   \n1.2.826.0.1.3680043.2.1125.1.641969959866553451...  1.2.840.10008.5.1.4.1.1.2   \n\n                                                    SOP Class UID  \\\n1.2.826.0.1.3680043.2.1125.1.663761548252932059...            195   \n1.2.826.0.1.3680043.2.1125.1.688789599848377264...            240   \n1.2.826.0.1.3680043.2.1125.1.644314406605294134...            216   \n1.2.826.0.1.3680043.2.1125.1.541969314475412820...            221   \n1.2.826.0.1.3680043.2.1125.1.641969959866553451...            210   \n\n                                                    Number of Images  \\\n1.2.826.0.1.3680043.2.1125.1.663761548252932059...               102   \n1.2.826.0.1.3680043.2.1125.1.688789599848377264...               126   \n1.2.826.0.1.3680043.2.1125.1.644314406605294134...               113   \n1.2.826.0.1.3680043.2.1125.1.541969314475412820...               116   \n1.2.826.0.1.3680043.2.1125.1.641969959866553451...               110   \n\n                                                   File Size  \\\n1.2.826.0.1.3680043.2.1125.1.663761548252932059...     47 MB   \n1.2.826.0.1.3680043.2.1125.1.688789599848377264...     12 MB   \n1.2.826.0.1.3680043.2.1125.1.644314406605294134...     51 MB   \n1.2.826.0.1.3680043.2.1125.1.541969314475412820...     14 MB   \n1.2.826.0.1.3680043.2.1125.1.641969959866553451...     36 MB   \n\n                                                                                        File Location  \\\n1.2.826.0.1.3680043.2.1125.1.663761548252932059...  .\\Pancreas-CT\\PANCREAS_0002\\11-24-2015-PANCREA...   \n1.2.826.0.1.3680043.2.1125.1.688789599848377264...  .\\Pancreas-CT\\PANCREAS_0001\\11-24-2015-PANCREA...   \n1.2.826.0.1.3680043.2.1125.1.644314406605294134...  .\\Pancreas-CT\\PANCREAS_0003\\11-24-2015-PANCREA...   \n1.2.826.0.1.3680043.2.1125.1.541969314475412820...  .\\Pancreas-CT\\PANCREAS_0004\\11-24-2015-PANCREA...   \n1.2.826.0.1.3680043.2.1125.1.641969959866553451...  .\\Pancreas-CT\\PANCREAS_0005\\11-24-2015-PANCREA...   \n\n                                                         Download Timestamp  \n1.2.826.0.1.3680043.2.1125.1.663761548252932059...  2022-04-21T11:40:19.813  \n1.2.826.0.1.3680043.2.1125.1.688789599848377264...  2022-04-21T11:41:15.234  \n1.2.826.0.1.3680043.2.1125.1.644314406605294134...   2022-04-21T11:43:27.53  \n1.2.826.0.1.3680043.2.1125.1.541969314475412820...  2022-04-21T11:43:41.702  \n1.2.826.0.1.3680043.2.1125.1.641969959866553451...  2022-04-21T11:44:11.927  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Series UID</th>\n      <th>Collection</th>\n      <th>3rd Party Analysis</th>\n      <th>Data Description URI</th>\n      <th>Subject ID</th>\n      <th>Study UID</th>\n      <th>Study Description</th>\n      <th>Study Date</th>\n      <th>Series Description</th>\n      <th>Manufacturer</th>\n      <th>Modality</th>\n      <th>SOP Class Name</th>\n      <th>SOP Class UID</th>\n      <th>Number of Images</th>\n      <th>File Size</th>\n      <th>File Location</th>\n      <th>Download Timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1.2.826.0.1.3680043.2.1125.1.66376154825293205999744306285863502</th>\n      <td>Pancreas-CT</td>\n      <td>NaN</td>\n      <td>https://doi.org/10.7937/K9/TCIA.2016.tNB1kqBU</td>\n      <td>PANCREAS_0002</td>\n      <td>1.2.826.0.1.3680043.2.1125.1.67817772420731955...</td>\n      <td>Pancreas</td>\n      <td>11-24-2015</td>\n      <td>Pancreas</td>\n      <td>NaN</td>\n      <td>CT</td>\n      <td>CT Image Storage</td>\n      <td>1.2.840.10008.5.1.4.1.1.2</td>\n      <td>195</td>\n      <td>102</td>\n      <td>47 MB</td>\n      <td>.\\Pancreas-CT\\PANCREAS_0002\\11-24-2015-PANCREA...</td>\n      <td>2022-04-21T11:40:19.813</td>\n    </tr>\n    <tr>\n      <th>1.2.826.0.1.3680043.2.1125.1.68878959984837726447916707551399667</th>\n      <td>Pancreas-CT</td>\n      <td>NaN</td>\n      <td>https://doi.org/10.7937/K9/TCIA.2016.tNB1kqBU</td>\n      <td>PANCREAS_0001</td>\n      <td>1.2.826.0.1.3680043.2.1125.1.38381854871216336...</td>\n      <td>Pancreas</td>\n      <td>11-24-2015</td>\n      <td>Pancreas</td>\n      <td>NaN</td>\n      <td>CT</td>\n      <td>CT Image Storage</td>\n      <td>1.2.840.10008.5.1.4.1.1.2</td>\n      <td>240</td>\n      <td>126</td>\n      <td>12 MB</td>\n      <td>.\\Pancreas-CT\\PANCREAS_0001\\11-24-2015-PANCREA...</td>\n      <td>2022-04-21T11:41:15.234</td>\n    </tr>\n    <tr>\n      <th>1.2.826.0.1.3680043.2.1125.1.64431440660529413465820250742459468</th>\n      <td>Pancreas-CT</td>\n      <td>NaN</td>\n      <td>https://doi.org/10.7937/K9/TCIA.2016.tNB1kqBU</td>\n      <td>PANCREAS_0003</td>\n      <td>1.2.826.0.1.3680043.2.1125.1.88257539048181233...</td>\n      <td>Pancreas</td>\n      <td>11-24-2015</td>\n      <td>Pancreas</td>\n      <td>NaN</td>\n      <td>CT</td>\n      <td>CT Image Storage</td>\n      <td>1.2.840.10008.5.1.4.1.1.2</td>\n      <td>216</td>\n      <td>113</td>\n      <td>51 MB</td>\n      <td>.\\Pancreas-CT\\PANCREAS_0003\\11-24-2015-PANCREA...</td>\n      <td>2022-04-21T11:43:27.53</td>\n    </tr>\n    <tr>\n      <th>1.2.826.0.1.3680043.2.1125.1.54196931447541282010320970741324542</th>\n      <td>Pancreas-CT</td>\n      <td>NaN</td>\n      <td>https://doi.org/10.7937/K9/TCIA.2016.tNB1kqBU</td>\n      <td>PANCREAS_0004</td>\n      <td>1.2.826.0.1.3680043.2.1125.1.45801723417932600...</td>\n      <td>Pancreas</td>\n      <td>11-24-2015</td>\n      <td>Pancreas</td>\n      <td>NaN</td>\n      <td>CT</td>\n      <td>CT Image Storage</td>\n      <td>1.2.840.10008.5.1.4.1.1.2</td>\n      <td>221</td>\n      <td>116</td>\n      <td>14 MB</td>\n      <td>.\\Pancreas-CT\\PANCREAS_0004\\11-24-2015-PANCREA...</td>\n      <td>2022-04-21T11:43:41.702</td>\n    </tr>\n    <tr>\n      <th>1.2.826.0.1.3680043.2.1125.1.64196995986655345161142945283707267</th>\n      <td>Pancreas-CT</td>\n      <td>NaN</td>\n      <td>https://doi.org/10.7937/K9/TCIA.2016.tNB1kqBU</td>\n      <td>PANCREAS_0005</td>\n      <td>1.2.826.0.1.3680043.2.1125.1.29048236109077859...</td>\n      <td>Pancreas</td>\n      <td>11-24-2015</td>\n      <td>Pancreas</td>\n      <td>NaN</td>\n      <td>CT</td>\n      <td>CT Image Storage</td>\n      <td>1.2.840.10008.5.1.4.1.1.2</td>\n      <td>210</td>\n      <td>110</td>\n      <td>36 MB</td>\n      <td>.\\Pancreas-CT\\PANCREAS_0005\\11-24-2015-PANCREA...</td>\n      <td>2022-04-21T11:44:11.927</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"# ============================================================\n# CREATE NORMAL vs PANCREATIC CANCER DATASET (ONE FILE)\n# Pancreas-CT (Normal) + MSD Task-07 (Cancer)\n# ============================================================\n\nimport os\nimport cv2\nimport numpy as np\nimport pydicom\nimport nibabel as nib\nimport shutil\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n\n# ============================================================\n# PATHS\n# ============================================================\n\nPANCREAS_CT_ROOT = \"/kaggle/input/pancreas-ct/Pancreas-CT/Pancreas-CT\"\nMSD_BASE = \"/kaggle/input/pancreatic-cancer/Task07_Pancreas\"\n\nOUT_ROOT = \"/kaggle/working/Pancreas_Classification_Dataset\"\n\nIMG_SIZE = 224\nMAX_SLICES = 10   # slices per patient (memory-safe)\nTEST_RATIO = 0.2\n\n# ============================================================\n# CREATE OUTPUT FOLDERS\n# ============================================================\n\nfor split in [\"train\", \"test\"]:\n    for cls in [\"normal\", \"cancer\"]:\n        os.makedirs(os.path.join(OUT_ROOT, split, cls), exist_ok=True)\n\n# ============================================================\n# PANCREAS-CT (NORMAL) LOADER\n# ============================================================\n\ndef load_pancreas_ct(patient_id):\n    patient_path = os.path.join(PANCREAS_CT_ROOT, patient_id)\n    slices = []\n\n    for root, _, files in os.walk(patient_path):\n        for f in files:\n            if f.endswith(\".dcm\"):\n                dcm = pydicom.dcmread(os.path.join(root, f))\n                img = dcm.pixel_array.astype(np.float32)\n                img = np.clip(img, -1000, 400)\n                img = (img + 1000) / 1400\n                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n                slices.append(img)\n\n    if len(slices) > MAX_SLICES:\n        idx = np.linspace(0, len(slices)-1, MAX_SLICES).astype(int)\n        slices = [slices[i] for i in idx]\n\n    return slices\n\n# ============================================================\n# MSD TASK-07 (CANCER) LOADER (.nii / .nii.gz)\n# ============================================================\n\ndef load_msd_case(nii_path):\n    vol = nib.load(nii_path).get_fdata()\n    slices = []\n\n    for i in range(vol.shape[2]):\n        img = vol[:, :, i]\n        img = np.clip(img, -1000, 400)\n        img = (img + 1000) / 1400\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n        slices.append(img)\n\n    if len(slices) > MAX_SLICES:\n        idx = np.linspace(0, len(slices)-1, MAX_SLICES).astype(int)\n        slices = [slices[i] for i in idx]\n\n    return slices\n\n# ============================================================\n# COLLECT NORMAL PATIENTS\n# ============================================================\n\nnormal_patients = sorted([\n    p for p in os.listdir(PANCREAS_CT_ROOT)\n    if p.startswith(\"PANCREAS_\")\n])\n\nprint(\"Total normal patients:\", len(normal_patients))\n\n# ============================================================\n# COLLECT CANCER PATIENTS (imagesTr + imagesTs)\n# ============================================================\n\ncancer_patients = []\n\nfor sub in [\"imagesTr\", \"imagesTs\"]:\n    folder = os.path.join(MSD_BASE, sub)\n    if os.path.exists(folder):\n        cancer_patients += [\n            os.path.join(folder, f)\n            for f in os.listdir(folder)\n            if (f.endswith(\".nii\") or f.endswith(\".nii.gz\")) and not f.startswith(\"._\")\n        ]\n\nprint(\"Total cancer patients:\", len(cancer_patients))\n\nif len(cancer_patients) == 0:\n    raise RuntimeError(\"No cancer volumes found. Check MSD dataset path.\")\n\n# ============================================================\n# PATIENT-LEVEL SPLIT\n# ============================================================\n\ntrain_n, test_n = train_test_split(\n    normal_patients, test_size=TEST_RATIO, random_state=42\n)\n\ntrain_c, test_c = train_test_split(\n    cancer_patients, test_size=TEST_RATIO, random_state=42\n)\n\nprint(\"Train normal:\", len(train_n), \" Test normal:\", len(test_n))\nprint(\"Train cancer:\", len(train_c), \" Test cancer:\", len(test_c))\n\n# ============================================================\n# SAVE NORMAL IMAGES\n# ============================================================\n\nprint(\"\\nSaving NORMAL images...\")\n\nfor pid in tqdm(train_n):\n    slices = load_pancreas_ct(pid)\n    for i, img in enumerate(slices):\n        cv2.imwrite(\n            f\"{OUT_ROOT}/train/normal/{pid}_{i:03d}.png\",\n            (img * 255).astype(np.uint8)\n        )\n\nfor pid in tqdm(test_n):\n    slices = load_pancreas_ct(pid)\n    for i, img in enumerate(slices):\n        cv2.imwrite(\n            f\"{OUT_ROOT}/test/normal/{pid}_{i:03d}.png\",\n            (img * 255).astype(np.uint8)\n        )\n\n# ============================================================\n# SAVE CANCER IMAGES\n# ============================================================\n\nprint(\"\\nSaving CANCER images...\")\n\nfor path in tqdm(train_c):\n    pid = os.path.splitext(os.path.basename(path))[0]\n    slices = load_msd_case(path)\n    for i, img in enumerate(slices):\n        cv2.imwrite(\n            f\"{OUT_ROOT}/train/cancer/{pid}_{i:03d}.png\",\n            (img * 255).astype(np.uint8)\n        )\n\nfor path in tqdm(test_c):\n    pid = os.path.splitext(os.path.basename(path))[0]\n    slices = load_msd_case(path)\n    for i, img in enumerate(slices):\n        cv2.imwrite(\n            f\"{OUT_ROOT}/test/cancer/{pid}_{i:03d}.png\",\n            (img * 255).astype(np.uint8)\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T04:48:38.234241Z","iopub.execute_input":"2026-02-09T04:48:38.234922Z","iopub.status.idle":"2026-02-09T05:03:16.715693Z","shell.execute_reply.started":"2026-02-09T04:48:38.234893Z","shell.execute_reply":"2026-02-09T05:03:16.714917Z"}},"outputs":[{"name":"stdout","text":"Total normal patients: 80\nTotal cancer patients: 420\nTrain normal: 64  Test normal: 16\nTrain cancer: 336  Test cancer: 84\n\nSaving NORMAL images...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [02:18<00:00,  2.17s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:32<00:00,  2.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nSaving CANCER images...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 336/336 [09:21<00:00,  1.67s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84/84 [02:23<00:00,  1.71s/it]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ============================================================\n# ZIP DATASET FOR DOWNLOAD\n# ============================================================\n\nzip_path = \"/kaggle/working/Pancreas_Classification_Dataset\"\nshutil.make_archive(zip_path, \"zip\", OUT_ROOT)\n\nprint(\"\\nâœ… DATASET CREATED SUCCESSFULLY!\")\nprint(\"ðŸ“¦ ZIP FILE:\", zip_path + \".zip\")\nprint(\"â¬‡ï¸ You can now download and reuse this dataset anytime.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:03:27.155298Z","iopub.execute_input":"2026-02-09T05:03:27.156122Z","iopub.status.idle":"2026-02-09T05:03:31.956378Z","shell.execute_reply.started":"2026-02-09T05:03:27.156093Z","shell.execute_reply":"2026-02-09T05:03:31.955729Z"}},"outputs":[{"name":"stdout","text":"\nâœ… DATASET CREATED SUCCESSFULLY!\nðŸ“¦ ZIP FILE: /kaggle/working/Pancreas_Classification_Dataset.zip\nâ¬‡ï¸ You can now download and reuse this dataset anytime.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ============================================================\n# SAVE PATIENT ID SPLITS (FOR REPRODUCIBILITY)\n# ============================================================\n\nwith open(os.path.join(OUT_ROOT, \"train_normal_patients.txt\"), \"w\") as f:\n    for pid in train_n:\n        f.write(pid + \"\\n\")\n\nwith open(os.path.join(OUT_ROOT, \"test_normal_patients.txt\"), \"w\") as f:\n    for pid in test_n:\n        f.write(pid + \"\\n\")\n\nwith open(os.path.join(OUT_ROOT, \"train_cancer_patients.txt\"), \"w\") as f:\n    for path in train_c:\n        f.write(os.path.basename(path) + \"\\n\")\n\nwith open(os.path.join(OUT_ROOT, \"test_cancer_patients.txt\"), \"w\") as f:\n    for path in test_c:\n        f.write(os.path.basename(path) + \"\\n\")\n\nprint(\"Patient split files saved to:\", OUT_ROOT)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:03:39.907151Z","iopub.execute_input":"2026-02-09T05:03:39.907552Z","iopub.status.idle":"2026-02-09T05:03:39.916130Z","shell.execute_reply.started":"2026-02-09T05:03:39.907522Z","shell.execute_reply":"2026-02-09T05:03:39.915533Z"}},"outputs":[{"name":"stdout","text":"Patient split files saved to: /kaggle/working/Pancreas_Classification_Dataset\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\n\nROOT = \"/kaggle/working/Pancreas_Classification_Dataset\"\n\nfiles_to_print = [\n    \"train_normal_patients.txt\",\n    \"test_normal_patients.txt\",\n    \"train_cancer_patients.txt\",\n    \"test_cancer_patients.txt\",\n]\n\nprint(\"ðŸ“‚ Files in dataset root:\")\nprint(os.listdir(ROOT))\n\nprint(\"\\n\" + \"=\"*60)\n\nfor fname in files_to_print:\n    path = os.path.join(ROOT, fname)\n    print(f\"\\nðŸ“„ {fname}\")\n    print(\"-\" * 40)\n    if os.path.exists(path):\n        with open(path, \"r\") as f:\n            print(f.read())\n    else:\n        print(\"âŒ File not found\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:05:51.549399Z","iopub.execute_input":"2026-02-09T05:05:51.550283Z","iopub.status.idle":"2026-02-09T05:05:51.557336Z","shell.execute_reply.started":"2026-02-09T05:05:51.550249Z","shell.execute_reply":"2026-02-09T05:05:51.556656Z"}},"outputs":[{"name":"stdout","text":"ðŸ“‚ Files in dataset root:\n['test_normal_patients.txt', 'train_normal_patients.txt', 'train', 'test_cancer_patients.txt', 'train_cancer_patients.txt', 'test']\n\n============================================================\n\nðŸ“„ train_normal_patients.txt\n----------------------------------------\nPANCREAS_0076\nPANCREAS_0063\nPANCREAS_0057\nPANCREAS_0042\nPANCREAS_0010\nPANCREAS_0066\nPANCREAS_0006\nPANCREAS_0049\nPANCREAS_0036\nPANCREAS_0064\nPANCREAS_0044\nPANCREAS_0056\nPANCREAS_0017\nPANCREAS_0041\nPANCREAS_0058\nPANCREAS_0082\nPANCREAS_0008\nPANCREAS_0052\nPANCREAS_0055\nPANCREAS_0020\nPANCREAS_0068\nPANCREAS_0027\nPANCREAS_0046\nPANCREAS_0014\nPANCREAS_0079\nPANCREAS_0004\nPANCREAS_0018\nPANCREAS_0040\nPANCREAS_0009\nPANCREAS_0067\nPANCREAS_0007\nPANCREAS_0038\nPANCREAS_0075\nPANCREAS_0060\nPANCREAS_0048\nPANCREAS_0081\nPANCREAS_0016\nPANCREAS_0029\nPANCREAS_0043\nPANCREAS_0028\nPANCREAS_0050\nPANCREAS_0026\nPANCREAS_0045\nPANCREAS_0080\nPANCREAS_0059\nPANCREAS_0012\nPANCREAS_0034\nPANCREAS_0078\nPANCREAS_0061\nPANCREAS_0065\nPANCREAS_0072\nPANCREAS_0039\nPANCREAS_0031\nPANCREAS_0002\nPANCREAS_0054\nPANCREAS_0022\nPANCREAS_0003\nPANCREAS_0024\nPANCREAS_0077\nPANCREAS_0021\nPANCREAS_0062\nPANCREAS_0074\nPANCREAS_0015\nPANCREAS_0053\n\n\nðŸ“„ test_normal_patients.txt\n----------------------------------------\nPANCREAS_0032\nPANCREAS_0001\nPANCREAS_0023\nPANCREAS_0033\nPANCREAS_0019\nPANCREAS_0030\nPANCREAS_0011\nPANCREAS_0073\nPANCREAS_0005\nPANCREAS_0013\nPANCREAS_0051\nPANCREAS_0035\nPANCREAS_0069\nPANCREAS_0037\nPANCREAS_0071\nPANCREAS_0047\n\n\nðŸ“„ train_cancer_patients.txt\n----------------------------------------\npancreas_045.nii\npancreas_111.nii\npancreas_296.nii\npancreas_066.nii\npancreas_282.nii\npancreas_156.nii\npancreas_240.nii\npancreas_361.nii\npancreas_110.nii\npancreas_247.nii\npancreas_388.nii\npancreas_050.nii\npancreas_119.nii\npancreas_090.nii\npancreas_082.nii\npancreas_020.nii\npancreas_329.nii\npancreas_105.nii\npancreas_324.nii\npancreas_089.nii\npancreas_143.nii\npancreas_254.nii\npancreas_126.nii\npancreas_059.nii\npancreas_256.nii\npancreas_064.nii\npancreas_046.nii\npancreas_280.nii\npancreas_158.nii\npancreas_151.nii\npancreas_112.nii\npancreas_399.nii\npancreas_188.nii\npancreas_397.nii\npancreas_260.nii\npancreas_048.nii\npancreas_018.nii\npancreas_125.nii\npancreas_002.nii\npancreas_264.nii\npancreas_283.nii\npancreas_248.nii\npancreas_127.nii\npancreas_217.nii\npancreas_383.nii\npancreas_051.nii\npancreas_137.nii\npancreas_403.nii\npancreas_404.nii\npancreas_194.nii\npancreas_181.nii\npancreas_031.nii\npancreas_237.nii\npancreas_200.nii\npancreas_259.nii\npancreas_136.nii\npancreas_196.nii\npancreas_318.nii\npancreas_343.nii\npancreas_365.nii\npancreas_325.nii\npancreas_131.nii\npancreas_104.nii\npancreas_331.nii\npancreas_295.nii\npancreas_222.nii\npancreas_357.nii\npancreas_114.nii\npancreas_243.nii\npancreas_120.nii\npancreas_097.nii\npancreas_163.nii\npancreas_306.nii\npancreas_017.nii\npancreas_232.nii\npancreas_373.nii\npancreas_229.nii\npancreas_379.nii\npancreas_008.nii\npancreas_309.nii\npancreas_129.nii\npancreas_013.nii\npancreas_198.nii\npancreas_148.nii\npancreas_034.nii\npancreas_367.nii\npancreas_098.nii\npancreas_363.nii\npancreas_108.nii\npancreas_191.nii\npancreas_149.nii\npancreas_419.nii\npancreas_075.nii\npancreas_287.nii\npancreas_354.nii\npancreas_164.nii\npancreas_192.nii\npancreas_204.nii\npancreas_271.nii\npancreas_321.nii\npancreas_312.nii\npancreas_417.nii\npancreas_288.nii\npancreas_291.nii\npancreas_193.nii\npancreas_100.nii\npancreas_004.nii\npancreas_069.nii\npancreas_215.nii\npancreas_323.nii\npancreas_286.nii\npancreas_372.nii\npancreas_207.nii\npancreas_197.nii\npancreas_019.nii\npancreas_068.nii\npancreas_118.nii\npancreas_389.nii\npancreas_003.nii\npancreas_021.nii\npancreas_290.nii\npancreas_157.nii\npancreas_249.nii\npancreas_410.nii\npancreas_274.nii\npancreas_267.nii\npancreas_080.nii\npancreas_225.nii\npancreas_154.nii\npancreas_185.nii\npancreas_278.nii\npancreas_043.nii\npancreas_116.nii\npancreas_016.nii\npancreas_298.nii\npancreas_107.nii\npancreas_063.nii\npancreas_356.nii\npancreas_073.nii\npancreas_170.nii\npancreas_277.nii\npancreas_263.nii\npancreas_352.nii\npancreas_095.nii\npancreas_128.nii\npancreas_421.nii\npancreas_124.nii\npancreas_349.nii\npancreas_026.nii\npancreas_220.nii\npancreas_416.nii\npancreas_203.nii\npancreas_300.nii\npancreas_177.nii\npancreas_187.nii\npancreas_412.nii\npancreas_297.nii\npancreas_327.nii\npancreas_173.nii\npancreas_252.nii\npancreas_044.nii\npancreas_368.nii\npancreas_360.nii\npancreas_072.nii\npancreas_208.nii\npancreas_171.nii\npancreas_065.nii\npancreas_234.nii\npancreas_353.nii\npancreas_086.nii\npancreas_405.nii\npancreas_233.nii\npancreas_092.nii\npancreas_025.nii\npancreas_012.nii\npancreas_261.nii\npancreas_096.nii\npancreas_227.nii\npancreas_206.nii\npancreas_420.nii\npancreas_056.nii\npancreas_047.nii\npancreas_415.nii\npancreas_221.nii\npancreas_391.nii\npancreas_014.nii\npancreas_409.nii\npancreas_272.nii\npancreas_303.nii\npancreas_402.nii\npancreas_178.nii\npancreas_103.nii\npancreas_029.nii\npancreas_346.nii\npancreas_165.nii\npancreas_155.nii\npancreas_231.nii\npancreas_040.nii\npancreas_251.nii\npancreas_332.nii\npancreas_052.nii\npancreas_374.nii\npancreas_160.nii\npancreas_364.nii\npancreas_250.nii\npancreas_057.nii\npancreas_005.nii\npancreas_370.nii\npancreas_322.nii\npancreas_345.nii\npancreas_030.nii\npancreas_293.nii\npancreas_394.nii\npancreas_224.nii\npancreas_226.nii\npancreas_153.nii\npancreas_301.nii\npancreas_302.nii\npancreas_060.nii\npancreas_179.nii\npancreas_313.nii\npancreas_342.nii\npancreas_174.nii\npancreas_236.nii\npancreas_182.nii\npancreas_109.nii\npancreas_284.nii\npancreas_071.nii\npancreas_315.nii\npancreas_205.nii\npancreas_099.nii\npancreas_216.nii\npancreas_398.nii\npancreas_028.nii\npancreas_341.nii\npancreas_235.nii\npancreas_152.nii\npancreas_316.nii\npancreas_378.nii\npancreas_320.nii\npancreas_175.nii\npancreas_289.nii\npancreas_400.nii\npancreas_054.nii\npancreas_035.nii\npancreas_032.nii\npancreas_078.nii\npancreas_121.nii\npancreas_039.nii\npancreas_242.nii\npancreas_041.nii\npancreas_085.nii\npancreas_350.nii\npancreas_414.nii\npancreas_266.nii\npancreas_189.nii\npancreas_023.nii\npancreas_258.nii\npancreas_162.nii\npancreas_337.nii\npancreas_053.nii\npancreas_347.nii\npancreas_393.nii\npancreas_214.nii\npancreas_091.nii\npancreas_145.nii\npancreas_106.nii\npancreas_223.nii\npancreas_167.nii\npancreas_209.nii\npancreas_049.nii\npancreas_183.nii\npancreas_362.nii\npancreas_386.nii\npancreas_037.nii\npancreas_334.nii\npancreas_147.nii\npancreas_265.nii\npancreas_142.nii\npancreas_304.nii\npancreas_027.nii\npancreas_382.nii\npancreas_135.nii\npancreas_326.nii\npancreas_132.nii\npancreas_058.nii\npancreas_299.nii\npancreas_292.nii\npancreas_257.nii\npancreas_134.nii\npancreas_042.nii\npancreas_390.nii\npancreas_115.nii\npancreas_141.nii\npancreas_413.nii\npancreas_275.nii\npancreas_146.nii\npancreas_199.nii\npancreas_074.nii\npancreas_102.nii\npancreas_062.nii\npancreas_006.nii\npancreas_406.nii\npancreas_117.nii\npancreas_308.nii\npancreas_079.nii\npancreas_087.nii\npancreas_333.nii\npancreas_130.nii\npancreas_007.nii\npancreas_244.nii\npancreas_024.nii\npancreas_358.nii\npancreas_307.nii\npancreas_317.nii\npancreas_371.nii\npancreas_366.nii\npancreas_150.nii\npancreas_239.nii\npancreas_001.nii\npancreas_377.nii\npancreas_396.nii\npancreas_339.nii\npancreas_384.nii\npancreas_380.nii\npancreas_038.nii\npancreas_070.nii\npancreas_140.nii\npancreas_338.nii\npancreas_138.nii\npancreas_241.nii\npancreas_262.nii\npancreas_246.nii\npancreas_336.nii\npancreas_359.nii\npancreas_113.nii\n\n\nðŸ“„ test_cancer_patients.txt\n----------------------------------------\npancreas_253.nii\npancreas_408.nii\npancreas_159.nii\npancreas_184.nii\npancreas_123.nii\npancreas_392.nii\npancreas_083.nii\npancreas_276.nii\npancreas_328.nii\npancreas_230.nii\npancreas_084.nii\npancreas_285.nii\npancreas_335.nii\npancreas_101.nii\npancreas_281.nii\npancreas_139.nii\npancreas_211.nii\npancreas_269.nii\npancreas_348.nii\npancreas_077.nii\npancreas_186.nii\npancreas_351.nii\npancreas_314.nii\npancreas_213.nii\npancreas_311.nii\npancreas_133.nii\npancreas_369.nii\npancreas_161.nii\npancreas_010.nii\npancreas_375.nii\npancreas_319.nii\npancreas_169.nii\npancreas_228.nii\npancreas_268.nii\npancreas_273.nii\npancreas_385.nii\npancreas_061.nii\npancreas_210.nii\npancreas_355.nii\npancreas_270.nii\npancreas_387.nii\npancreas_255.nii\npancreas_202.nii\npancreas_310.nii\npancreas_180.nii\npancreas_176.nii\npancreas_094.nii\npancreas_245.nii\npancreas_190.nii\npancreas_067.nii\npancreas_093.nii\npancreas_381.nii\npancreas_088.nii\npancreas_015.nii\npancreas_168.nii\npancreas_330.nii\npancreas_305.nii\npancreas_166.nii\npancreas_294.nii\npancreas_122.nii\npancreas_033.nii\npancreas_219.nii\npancreas_172.nii\npancreas_144.nii\npancreas_279.nii\npancreas_022.nii\npancreas_081.nii\npancreas_055.nii\npancreas_218.nii\npancreas_407.nii\npancreas_395.nii\npancreas_340.nii\npancreas_238.nii\npancreas_344.nii\npancreas_411.nii\npancreas_201.nii\npancreas_076.nii\npancreas_418.nii\npancreas_036.nii\npancreas_009.nii\npancreas_376.nii\npancreas_195.nii\npancreas_401.nii\npancreas_212.nii\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ============================================================\n# PANCREATIC CANCER CLASSIFICATION\n# Pancreas-CT (Normal) + MSD Task07 (Cancer)\n# Slice â†’ Patient Aggregation\n# 3-Fold CV + Per-Fold Patient-Level Evaluation\n# ============================================================\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"   # force GPU 0\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"   # cleaner logs\n\nimport os, cv2, pydicom, nibabel as nib\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import (\n    classification_report, confusion_matrix,\n    roc_auc_score, roc_curve, cohen_kappa_score\n)\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:11:56.974311Z","iopub.execute_input":"2026-02-09T05:11:56.974982Z","iopub.status.idle":"2026-02-09T05:12:11.209129Z","shell.execute_reply.started":"2026-02-09T05:11:56.974951Z","shell.execute_reply":"2026-02-09T05:12:11.208409Z"}},"outputs":[{"name":"stderr","text":"2026-02-09 05:11:58.545188: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770613918.709964      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770613918.766570      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770613919.184637      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770613919.184664      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770613919.184667      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770613919.184669      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ============================================================\n# GPU SETUP\n# ============================================================\nprint(\"TensorFlow version:\", tf.__version__)\n\ngpus = tf.config.list_physical_devices(\"GPU\")\nif not gpus:\n    raise RuntimeError(\"âŒ GPU NOT FOUND â€” training aborted\")\n\ntry:\n    tf.config.set_visible_devices(gpus[0], \"GPU\")\n    tf.config.experimental.set_memory_growth(gpus[0], True)\n    tf.config.set_soft_device_placement(False)  # â— DO NOT allow CPU fallback\n    print(\"âœ… GPU FORCED:\", gpus[0].name)\nexcept RuntimeError as e:\n    print(\"GPU config error:\", e)\n\n# ============================================================\n# CONFIG\n# ============================================================\n\n@tf.function\ndef gpu_test():\n    with tf.device(\"/GPU:0\"):\n        a = tf.random.normal((5000, 5000))\n        b = tf.matmul(a, a)\n    return b\n\ngpu_test()\nprint(\"ðŸ”¥ GPU test computation completed\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:12:24.931422Z","iopub.execute_input":"2026-02-09T05:12:24.932462Z","iopub.status.idle":"2026-02-09T05:12:26.003769Z","shell.execute_reply.started":"2026-02-09T05:12:24.932430Z","shell.execute_reply":"2026-02-09T05:12:26.002951Z"}},"outputs":[{"name":"stdout","text":"TensorFlow version: 2.19.0\nâœ… GPU FORCED: /physical_device:GPU:0\nðŸ”¥ GPU test computation completed\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1770613945.831425      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ============================================================\n\nPANCREAS_CT_ROOT = \"/kaggle/input/pancreas-ct/Pancreas-CT/Pancreas-CT\"\nMSD_BASE = \"/kaggle/input/pancreatic-cancer/Task07_Pancreas\"\n\nIMG_SIZE = 224\nMAX_SLICES = 10\nEPOCHS = 20\nBATCH_SIZE = 32\nLR = 0.0001\nN_FOLDS = 3\n\nNORMAL_LABEL = 0\nCANCER_LABEL = 1\n\n# ============================================================\n# PREPROCESSING\n# ============================================================\ndef preprocess_slice(img):\n    img = np.clip(img, -1000, 400)\n    img = (img + 1000) / 1400.0\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    return img.astype(np.float32)\n\n# ============================================================\n# FAST LOADERS\n# ============================================================\ndef load_pancreas_ct_fast(pid):\n    root = os.path.join(PANCREAS_CT_ROOT, pid)\n    files = []\n    for r, _, fs in os.walk(root):\n        for f in fs:\n            if f.endswith(\".dcm\"):\n                try:\n                    p = os.path.join(r, f)\n                    ds = pydicom.dcmread(p, stop_before_pixels=True)\n                    files.append((getattr(ds, \"InstanceNumber\", 0), p))\n                except:\n                    pass\n    files.sort(key=lambda x: x[0])\n    slices = []\n    for _, p in files[:MAX_SLICES * 2]:\n        try:\n            ds = pydicom.dcmread(p)\n            slices.append(preprocess_slice(ds.pixel_array))\n            if len(slices) >= MAX_SLICES:\n                break\n        except:\n            pass\n    return slices\n\ndef load_msd_case_fast(path):\n    try:\n        img = nib.load(path)\n        vol = img.get_fdata()\n        idx = np.linspace(0, vol.shape[2]-1, MAX_SLICES).astype(int)\n        return [preprocess_slice(vol[:, :, i]) for i in idx]\n    except:\n        return []\n\n# ============================================================\n# DATASET GENERATOR\n# ============================================================\ncancer_paths_global = []\n\ndef slice_generator(pids, labels):\n    for pid, lbl in zip(pids, labels):\n        if pid.startswith(\"N_\"):\n            slices = load_pancreas_ct_fast(pid[2:])\n        else:\n            path = next((p for p in cancer_paths_global if os.path.basename(p) == pid[2:]), None)\n            if path is None:\n                continue\n            slices = load_msd_case_fast(path)\n\n        for s in slices:\n            yield np.stack([s]*3, -1), lbl\n\ndef build_dataset(pids, labels, shuffle=True):\n    ds = tf.data.Dataset.from_generator(\n        lambda: slice_generator(pids, labels),\n        output_signature=(\n            tf.TensorSpec((IMG_SIZE, IMG_SIZE, 3), tf.float32),\n            tf.TensorSpec((), tf.int32)\n        )\n    )\n    if shuffle:\n        ds = ds.shuffle(2048).repeat()\n    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n# ============================================================\n# DISCOVER DATASET\n# ============================================================\nnormal_ids = sorted([p for p in os.listdir(PANCREAS_CT_ROOT) if p.startswith(\"PANCREAS_\")])\n\ncancer_paths = []\nfor sub in [\"imagesTr\", \"imagesTs\"]:\n    folder = os.path.join(MSD_BASE, sub)\n    if os.path.exists(folder):\n        cancer_paths += [\n            os.path.join(folder, f)\n            for f in os.listdir(folder)\n            if f.endswith((\".nii\", \".nii.gz\"))\n        ]\n\ncancer_paths_global = cancer_paths\n\npatient_ids = np.array(\n    [\"N_\"+p for p in normal_ids] +\n    [\"C_\"+os.path.basename(p) for p in cancer_paths]\n)\nlabels = np.array(\n    [NORMAL_LABEL]*len(normal_ids) +\n    [CANCER_LABEL]*len(cancer_paths)\n)\n\nprint(f\"âœ… Dataset: {len(patient_ids)} patients\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:12:32.356346Z","iopub.execute_input":"2026-02-09T05:12:32.357012Z","iopub.status.idle":"2026-02-09T05:12:32.396093Z","shell.execute_reply.started":"2026-02-09T05:12:32.356981Z","shell.execute_reply":"2026-02-09T05:12:32.395461Z"}},"outputs":[{"name":"stdout","text":"âœ… Dataset: 509 patients\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ============================================================\n# MODEL (MobileNetV3 + CBAM + LASER)\n# ============================================================\nclass CBAM(layers.Layer):\n    def __init__(self, ch):\n        super().__init__()\n        self.avg = layers.GlobalAveragePooling2D()\n        self.fc = layers.Dense(ch, activation='sigmoid')\n\n    def call(self, x):\n        w = self.fc(self.avg(x))\n        return x * tf.reshape(w, (-1, 1, 1, x.shape[-1]))\n\nclass LASERAttention(layers.Layer):\n    def __init__(self, dim, heads):\n        super().__init__()\n        self.att = layers.MultiHeadAttention(heads, dim // heads)\n\n    def call(self, x):\n        return self.att(x, x)\n\ndef create_model():\n    base = keras.applications.MobileNetV3Small(\n        include_top=False, weights=\"imagenet\",\n        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n    )\n    base.trainable = False\n\n    x = CBAM(base.output.shape[-1])(base.output)\n    x = layers.Conv2D(128, 1)(x)\n\n    seq = layers.Reshape((-1, 128))(x)\n    att = LASERAttention(128, 8)(seq)\n    att = layers.GlobalAveragePooling1D()(att)\n\n    cnn = layers.GlobalAveragePooling2D()(x)\n\n    f = layers.Concatenate()([cnn, att])\n    f = layers.Dense(256, activation='relu')(f)\n    f = layers.Dropout(0.5)(f)\n\n    out = layers.Dense(1, activation='sigmoid')(f)\n\n    model = keras.Model(base.input, out)\n    \n    model.compile(\n        optimizer=keras.optimizers.Adam(LR),\n        loss=\"binary_crossentropy\",\n        metrics=[\"accuracy\", keras.metrics.AUC(name=\"auc\")]\n    )\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:13:04.161516Z","iopub.execute_input":"2026-02-09T05:13:04.162180Z","iopub.status.idle":"2026-02-09T05:13:04.171585Z","shell.execute_reply.started":"2026-02-09T05:13:04.162134Z","shell.execute_reply":"2026-02-09T05:13:04.170749Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from tensorflow.keras import layers, Model, regularizers\nfrom tensorflow.keras.applications import MobileNetV3Small\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n# 2. Attention modules & hybrid model\nclass CBAM(layers.Layer):\n    def __init__(self, filters, reduction=16, **kwargs):\n        super(CBAM, self).__init__(**kwargs)\n        self.avg_pool = layers.GlobalAveragePooling2D()\n        self.max_pool = layers.GlobalMaxPooling2D()\n        self.shared_dense_one = layers.Dense(max(1, filters // reduction), activation='relu', use_bias=False)\n        self.shared_dense_two = layers.Dense(filters, use_bias=False)\n        self.sigmoid = layers.Activation('sigmoid')\n\n    def call(self, inputs):\n        avg_out = self.shared_dense_two(self.shared_dense_one(self.avg_pool(inputs)))\n        max_out = self.shared_dense_two(self.shared_dense_one(self.max_pool(inputs)))\n        scale = self.sigmoid(avg_out + max_out)\n        scale = tf.expand_dims(tf.expand_dims(scale, axis=1), axis=1)\n        return inputs * scale\n\nclass LASERAttention(layers.Layer):\n    def __init__(self, embed_dim, num_heads, rank=16):\n        super(LASERAttention, self).__init__()\n        assert embed_dim % num_heads == 0\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.rank = rank\n        self.proj_dim = embed_dim // num_heads\n\n        self.q_proj = layers.Dense(embed_dim)\n        self.k_proj = layers.Dense(embed_dim)\n        self.v_proj = layers.Dense(embed_dim)\n        self.out_proj = layers.Dense(embed_dim)\n\n        self.U = self.add_weight(shape=(num_heads, rank, self.proj_dim), initializer=\"glorot_uniform\", trainable=True)\n        self.V = self.add_weight(shape=(num_heads, rank, self.proj_dim), initializer=\"glorot_uniform\", trainable=True)\n        self.last_attention = None\n\n    def call(self, inputs):\n        batch_size = tf.shape(inputs)[0]\n        seq_len = tf.shape(inputs)[1]\n\n        Q = self.q_proj(inputs)\n        K = self.k_proj(inputs)\n        V = self.v_proj(inputs)\n\n        Q = tf.reshape(Q, (batch_size, seq_len, self.num_heads, self.proj_dim))\n        K = tf.reshape(K, (batch_size, seq_len, self.num_heads, self.proj_dim))\n        V = tf.reshape(V, (batch_size, seq_len, self.num_heads, self.proj_dim))\n\n        Q = tf.transpose(Q, perm=[0, 2, 1, 3])\n        K = tf.transpose(K, perm=[0, 2, 1, 3])\n        V = tf.transpose(V, perm=[0, 2, 1, 3])\n\n        Q_lowrank = tf.einsum('bhqd,hrd->bhrq', Q, self.U)\n        Q_lowrank = tf.transpose(Q_lowrank, perm=[0, 1, 3, 2])\n        K_lowrank = tf.einsum('bhkd,hrd->bhrk', K, self.V)\n\n        attn = tf.matmul(Q_lowrank, K_lowrank) / tf.math.sqrt(tf.cast(self.rank, tf.float32))\n        attn = tf.nn.softmax(attn, axis=-1)\n\n        out = tf.matmul(attn, V)\n        out = tf.transpose(out, perm=[0, 2, 1, 3])\n        out = tf.reshape(out, (batch_size, seq_len, self.embed_dim))\n\n        self.last_attention = attn\n        return self.out_proj(out)\n\nclass TransformerEncoderLASERAttention(layers.Layer):\n    def __init__(self, embed_dim, num_heads, ff_dim, rank=16):\n        super(TransformerEncoderLASERAttention, self).__init__()\n        self.attention = LASERAttention(embed_dim, num_heads, rank=rank)\n        self.ffn = tf.keras.Sequential([layers.Dense(ff_dim, activation='relu'), layers.Dense(embed_dim)])\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.add1 = layers.Add(); self.add2 = layers.Add()\n\n    def call(self, inputs):\n        attn_output = self.attention(inputs)\n        out1 = self.add1([inputs, attn_output]); out1 = self.layernorm1(out1)\n        ffn_output = self.ffn(out1); out2 = self.add2([out1, ffn_output])\n        return self.layernorm2(out2)\n\nclass CTIModule(layers.Layer):\n    def __init__(self, output_dim):\n        super(CTIModule, self).__init__()\n        self.dense = layers.Dense(output_dim, activation='relu')\n    def call(self, inputs):\n        return self.dense(inputs)\n\ndef build_hybrid_model(input_shape=(224,224,3), num_classes=1, embed_dim=128, num_heads=4, ff_dim=256):\n    inputs = layers.Input(shape=input_shape)\n    mobilenet = MobileNetV3Small(include_top=False, input_shape=input_shape, weights='imagenet')\n    x = mobilenet(inputs)\n    x = CBAM(x.shape[-1])(x)\n    x = layers.Conv2D(embed_dim, kernel_size=1, name=\"proj_conv\")(x)\n\n    def reshape_for_transformer(t):\n        shape = tf.shape(t)\n        batch_size = shape[0]; h = shape[1]; w = shape[2]; c = shape[3]\n        seq_len = h * w\n        return tf.reshape(t, (batch_size, seq_len, c))\n\n    x_reshape = layers.Lambda(reshape_for_transformer, name=\"patchify\")(x)\n    transformer = TransformerEncoderLASERAttention(embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim)\n    x_transformed = transformer(x_reshape)\n\n    x_pooled = layers.GlobalAveragePooling1D(name=\"trans_avgpool\")(x_transformed)\n    cnn_pooled = layers.GlobalAveragePooling2D(name=\"cnn_avgpool\")(x)\n\n    fused = layers.Concatenate(name=\"fuse\")([cnn_pooled, x_pooled])\n    fused = CTIModule(embed_dim)(fused)\n    x = layers.Dropout(0.5)(fused)\n    x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n    x = layers.Dropout(0.5)(x)\n\n    if num_classes == 2:\n        outputs = layers.Dense(1, activation='sigmoid', name='pred')(x)\n    else:\n        outputs = layers.Dense(num_classes, activation='softmax', name='pred')(x)\n\n    model = Model(inputs, outputs)\n    model.transformer_layer = transformer\n\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:31:03.607354Z","iopub.execute_input":"2026-02-09T05:31:03.607965Z","iopub.status.idle":"2026-02-09T05:31:03.635259Z","shell.execute_reply.started":"2026-02-09T05:31:03.607934Z","shell.execute_reply":"2026-02-09T05:31:03.634385Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"model = build_hybrid_model(\n    input_shape=(224, 224, 3),\n    num_classes=1,\n    embed_dim=128,\n    num_heads=4,\n    ff_dim=256\n)\nmodel.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=LR),\n    loss=\"binary_crossentropy\",\n    metrics=[\n        \"accuracy\",\n        keras.metrics.AUC(name=\"auc\"),\n        keras.metrics.Precision(name=\"precision\"),\n        keras.metrics.Recall(name=\"recall\")\n    ])\n#def build_hybrid_model(input_shape=(224,224,3), num_classes=1, embed_dim=128, num_heads=4, ff_dim=256):\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:31:09.264891Z","iopub.execute_input":"2026-02-09T05:31:09.265244Z","iopub.status.idle":"2026-02-09T05:31:10.694439Z","shell.execute_reply.started":"2026-02-09T05:31:09.265204Z","shell.execute_reply":"2026-02-09T05:31:10.693754Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_8\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ input_layer_12      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\nâ”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ MobileNetV3Small    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m576\u001b[0m) â”‚    \u001b[38;5;34m939,120\u001b[0m â”‚ input_layer_12[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ cbam_7 (\u001b[38;5;33mCBAM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m576\u001b[0m) â”‚     \u001b[38;5;34m41,472\u001b[0m â”‚ MobileNetV3Smallâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ proj_conv (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m) â”‚     \u001b[38;5;34m73,856\u001b[0m â”‚ cbam_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ patchify (\u001b[38;5;33mLambda\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ proj_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ transformer_encodeâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â”‚    \u001b[38;5;34m136,576\u001b[0m â”‚ patchify[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mTransformerEncodeâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ cnn_avgpool         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ proj_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ trans_avgpool       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ transformer_encoâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ fuse (\u001b[38;5;33mConcatenate\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ cnn_avgpool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ trans_avgpool[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ cti_module_2        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m32,896\u001b[0m â”‚ fuse[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\nâ”‚ (\u001b[38;5;33mCTIModule\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_13          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ cti_module_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_43 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m33,024\u001b[0m â”‚ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_14          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ pred (\u001b[38;5;33mDense\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚        \u001b[38;5;34m257\u001b[0m â”‚ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ input_layer_12      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ MobileNetV3Small    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>) â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">939,120</span> â”‚ input_layer_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ cbam_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CBAM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>) â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,472</span> â”‚ MobileNetV3Smallâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ proj_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚ cbam_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ patchify (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ proj_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ transformer_encodeâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">136,576</span> â”‚ patchify[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncodeâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ cnn_avgpool         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ proj_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ trans_avgpool       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ transformer_encoâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ fuse (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ cnn_avgpool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ trans_avgpool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ cti_module_2        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚ fuse[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CTIModule</span>)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_13          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ cti_module_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_14          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ pred (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,257,201\u001b[0m (4.80 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,257,201</span> (4.80 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,245,089\u001b[0m (4.75 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,245,089</span> (4.75 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m12,112\u001b[0m (47.31 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,112</span> (47.31 KB)\n</pre>\n"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"# ============================================================\n# PATIENT-LEVEL PREDICTION\n# ============================================================\ndef patient_level_eval(pids, labels, model):\n    yt, yp, yprob = [], [], []\n    for pid, y in zip(pids, labels):\n        slices = load_pancreas_ct_fast(pid[2:]) if pid.startswith(\"N_\") \\\n            else load_msd_case_fast(\n                next(p for p in cancer_paths_global if os.path.basename(p) == pid[2:])\n            )\n        if not slices:\n            continue\n        X = np.array([np.stack([s]*3, -1) for s in slices])\n        probs = model.predict(X, verbose=0).mean()\n        yt.append(y)\n        yp.append(int(probs > 0.5))\n        yprob.append(probs)\n    return yt, yp, yprob\n\n# ============================================================\n# CROSS VALIDATION\n# ============================================================\nskf = StratifiedKFold(N_FOLDS, shuffle=True, random_state=42)\n\nresults = {\n    \"train_loss\": [], \"val_loss\": [],\n    \"train_acc\": [], \"val_acc\": [],\n    \"train_auc\": [], \"val_auc\": [],\n    \"fold_patients\": []\n}\n\nfor f, (tr, va) in enumerate(skf.split(patient_ids, labels)):\n    print(f\"\\n--- Fold {f+1} ---\")\n\n   # model = create_model()\n\n    train_ds = build_dataset(patient_ids[tr], labels[tr])\n    val_ds   = build_dataset(patient_ids[va], labels[va], shuffle=False)\n\n    hist = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=EPOCHS,\n        steps_per_epoch=len(tr) * MAX_SLICES // BATCH_SIZE,\n        validation_steps=max(1, len(va) * MAX_SLICES // BATCH_SIZE),\n        callbacks=[\n            keras.callbacks.EarlyStopping(\n                monitor=\"val_auc\",\n                mode=\"max\",\n                patience=5,\n                restore_best_weights=True\n            )\n        ],\n        verbose=1\n    )\n\n    results[\"train_loss\"].append(min(hist.history[\"loss\"]))\n    results[\"val_loss\"].append(min(hist.history[\"val_loss\"]))\n    results[\"train_acc\"].append(max(hist.history[\"accuracy\"]))\n    results[\"val_acc\"].append(max(hist.history[\"val_accuracy\"]))\n    results[\"train_auc\"].append(max(hist.history[\"auc\"]))\n    results[\"val_auc\"].append(max(hist.history[\"val_auc\"]))\n\n    yt, yp, ypr = patient_level_eval(patient_ids[va], labels[va], model)\n    results[\"fold_patients\"].append((yt, yp, ypr))\n\n    #print(classification_report(yt, yp, target_names=[\"Normal\", \"Cancer\"]),digits=4)\n    print(classification_report(yt,yp, target_names=[\"Normal\", \"Cancer\"], digits=4))\n    print(\"AUC:\", roc_auc_score(yt, ypr),\n          \"Kappa:\", cohen_kappa_score(yt, yp))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:31:46.812153Z","iopub.execute_input":"2026-02-09T05:31:46.812525Z"}},"outputs":[{"name":"stdout","text":"\n--- Fold 1 ---\nEpoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/keras/src/ops/nn.py:944: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n  warnings.warn(\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1770615336.094259     188 service.cc:152] XLA service 0x7874b8003e90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1770615336.094310     188 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1770615341.435636     188 cuda_dnn.cc:529] Loaded cuDNN version 91002\nI0000 00:00:1770615370.260442     188 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m768s\u001b[0m 5s/step - accuracy: 0.8067 - auc: 0.5000 - loss: 0.4703 - precision: 0.8067 - recall: 1.0000 - val_accuracy: 0.8402 - val_auc: 0.5000 - val_loss: 1.1669 - val_precision: 0.8402 - val_recall: 1.0000\nEpoch 2/20\n\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 4s/step - accuracy: 0.8103 - auc: 0.5000 - loss: 0.1633 - precision: 0.8103 - recall: 1.0000 - val_accuracy: 0.8402 - val_auc: 0.5000 - val_loss: 1.6596 - val_precision: 0.8402 - val_recall: 1.0000\nEpoch 3/20\n\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 5s/step - accuracy: 0.8098 - auc: 0.5000 - loss: 0.1470 - precision: 0.8098 - recall: 1.0000 - val_accuracy: 0.8402 - val_auc: 0.5000 - val_loss: 1.9997 - val_precision: 0.8402 - val_recall: 1.0000\nEpoch 4/20\n\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 5s/step - accuracy: 0.8233 - auc: 0.5000 - loss: 0.1337 - precision: 0.8233 - recall: 1.0000 - val_accuracy: 0.8402 - val_auc: 0.5000 - val_loss: 2.7067 - val_precision: 0.8402 - val_recall: 1.0000\nEpoch 5/20\n\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 5s/step - accuracy: 0.8285 - auc: 0.5000 - loss: 0.1219 - precision: 0.8285 - recall: 1.0000 - val_accuracy: 0.8402 - val_auc: 0.5000 - val_loss: 3.1291 - val_precision: 0.8402 - val_recall: 1.0000\nEpoch 6/20\n\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m523s\u001b[0m 5s/step - accuracy: 0.8363 - auc: 0.5000 - loss: 0.1109 - precision: 0.8363 - recall: 1.0000 - val_accuracy: 0.8402 - val_auc: 0.5000 - val_loss: 3.6185 - val_precision: 0.8402 - val_recall: 1.0000\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/keras/src/ops/nn.py:944: UserWarning: You are using a softmax over axis -1 of a tensor of shape (10, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n      Normal     0.0000    0.0000    0.0000        27\n      Cancer     0.8402    1.0000    0.9132       142\n\n    accuracy                         0.8402       169\n   macro avg     0.4201    0.5000    0.4566       169\nweighted avg     0.7060    0.8402    0.7673       169\n\nAUC: 0.5 Kappa: 0.0\n\n--- Fold 2 ---\nEpoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 4s/step - accuracy: 0.8110 - auc: 0.5000 - loss: 0.1623 - precision: 0.8110 - recall: 1.0000 - val_accuracy: 0.8373 - val_auc: 0.5000 - val_loss: 2.2747 - val_precision: 0.8373 - val_recall: 1.0000\nEpoch 2/20\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` {"cell_type":"code","source":"# ============================================================\n# FINAL COMBINED RESULTS\n# ============================================================\nall_y, all_p, all_pr = [], [], []\nfor yt, yp, ypr in results[\"fold_patients\"]:\n    all_y += yt\n    all_p += yp\n    all_pr += ypr\n\nprint(\"\\nFINAL RESULTS\")\nprint(\n    classification_report(\n        all_y,      \n        all_p,\n        target_names=[\"Normal\", \"Cancer\"],\n        digits=4\n    )\n)\nprint(\"Final AUC:\", roc_auc_score(all_y, all_pr))\n\n# Confusion Matrix\nplt.figure(figsize=(6,5))\nsns.heatmap(\n    confusion_matrix(all_y, all_p),\n    annot=True, fmt=\"d\", cmap=\"Blues\",\n    xticklabels=[\"Normal\",\"Cancer\"],\n    yticklabels=[\"Normal\",\"Cancer\"]\n)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Patient-Level Confusion Matrix (3-Fold CV)\")\nplt.tight_layout()\nplt.show()\n\n# ROC\nfpr, tpr, _ = roc_curve(all_y, all_pr)\nplt.plot(fpr, tpr, label=f\"AUC={roc_auc_score(all_y, all_pr):.4f}\")\nplt.plot([0,1],[0,1],'--')\nplt.legend(); plt.grid(); plt.show()\n\nprint(\"âœ… COMPLETE\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
